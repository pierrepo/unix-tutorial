# Automatiser l'analyse RNA-seq âš™ï¸

```{contents}
```

Dans la section prÃ©cÃ©dente, vous avez analysÃ© les donnÃ©es RNA-seq d'un seul Ã©chantillon en exÃ©cutant, une Ã  une, chaque Ã©tape de l'analyse (contrÃ´le qualitÃ©, alignement des *reads*, quantification...).

Nous allons maintenant automatiser l'analyse d'un Ã©chantillon en utilisant un script. Puis nous automatiserons l'analyse de plusieurs Ã©chantillons.

## VÃ©rifier l'environnement logiciel et les donnÃ©es

Si cela n'est pas dÃ©jÃ  fait, chargez les outils nÃ©cessaires Ã  l'analyse des donnÃ©es RNA-seq :

```bash
$ module load sra-tools fastqc star htseq cufflinks samtools
```

```{admonition} Rappel
:class: tip
La commande `module list` affiche les modules dÃ©jÃ  chargÃ©s.
```

VÃ©rifiez ensuite que vous Ãªtes bien dans le rÃ©pertoire `/shared/projects/202304_duo/$USER/rnaseq` avec la commande `pwd`. DÃ©placez-vous dans ce rÃ©pertoire si ce n'est pas le cas.

Supprimez les rÃ©pertoires qui contiennent les rÃ©sultats de l'analyse prÃ©cÃ©dente :

```bash
$ rm -rf genome_index reads_qc reads_map counts
```

```{warning}
Attention Ã  la commande `rm` qui supprime irrÃ©mÃ©diablement fichiers et rÃ©pertoires.
```

Enfin, vÃ©rifiez que les donnÃ©es RNA-seq et le gÃ©nome de *S. cerevisiae* sont bien disponibles :

```bash
$ tree
.
â”œâ”€â”€ genome
â”‚   â”œâ”€â”€ genes.gtf
â”‚   â””â”€â”€ genome.fa
â””â”€â”€ reads
    â”œâ”€â”€ SRR3405783.fastq.gz
    â”œâ”€â”€ SRR3405784.fastq.gz
    â””â”€â”€ SRR3405785.fastq.gz
```

## Variables Bash

Une variable va contenir de l'information qui sera utilisable autant de fois que nÃ©cessaire.

CrÃ©er des variables :

```bash
$ toto=33
$ t="salut"
```

```{warning}
Il faut coller le nom de la variable et son contenu au symbole `=`.
```

Afficher des variables :

```bash
$ echo $toto
33
$ echo "$t Pierre"
salut Pierre
```

La commande `echo` affiche une chaÃ®ne de caractÃ¨res, une variable, ou les deux.

Pour utiliser une variable (et accÃ©der Ã  son contenu), il faut prÃ©cÃ©der son nom du caractÃ¨re `$`. Attention, ne  confondez pas ce symbole avec celui qui dÃ©signe l'invite de commande de votre *shell* Linux.

Enfin, une bonne pratique consiste Ã  utiliser une variable avec le symbole `$` et son nom entre accolades :

```bash
$ echo ${toto}
33
$ echo "${t} Pierre"
salut Pierre
```

## Script Bash

Un script est un fichier texte qui contient des instructions Bash. Par convention, il porte l'extension `.sh`. L'objectif premier d'un script Bash est d'**automatiser l'exÃ©cution de plusieurs commandes** Bash, la plupart du temps pour manipuler ou analyser des fichiers.

Dans un script Bash :

- La premiÃ¨re ligne commence par `#! /bin/bash` et prÃ©cise Ã  l'ordinateur que le script est Ã©crit en Bash.
- Tout ce qui suit le symbole `#` est considÃ©rÃ© comme un commentaire et n'est donc pas traitÃ© par Bash.
- Le caractÃ¨re `\` en fin de ligne permet de continuer une instruction sur la ligne suivante.

## Automatiser l'analyse d'un Ã©chantillon

TÃ©lÃ©chargez dans un terminal de JupyterLab un premier script Bash ([`script_local_1.sh`](script_local_1.sh)) avec la commande `wget` :

```bash
$ wget https://raw.githubusercontent.com/pierrepo/unix-tutorial/master/tuto2/script_local_1.sh
```

Ouvrez ce script avec l'Ã©diteur de texte de JupyterLab. Pour cela, double-cliquez sur le nom du script dans le navigateur de fichiers (situÃ© Ã  gauche) de JupyterLab, .

Retrouvez Ã©galement dans ce script les diffÃ©rentes Ã©tapes de l'analyse RNA-seq que vous avez rÃ©alisÃ©es prÃ©cÃ©demment. Y-a-t-il des choses bizarres dont vous souhaiteriez des explications ? Si oui, notez-les, lancez-le script puis nous y reviendrons.

Lancez le script avec la commande :

```bash
$ bash script_local_1.sh
```

VÃ©rifiez que le dÃ©roulement du script se passe bien. Vous avez le temps de prendre un cafÃ©, voir plusieurs â˜• ðŸª â˜• ðŸª.

Une fois terminÃ©, Ã©valuez approximativement le temps qu'il a fallu au script 1 pour s'exÃ©cuter. Reportez dans le carnet de bord le numÃ©ro de l'Ã©chantillon analysÃ© et le temps d'exÃ©cution du script.

D'aprÃ¨s vous, quelle est l'Ã©tape la plus longue ? Combien de temps faudrait-il pour analyser les 3 Ã©chantillons ?

Utilisez enfin la commande `tree` pour contempler votre travail (ici avec l'Ã©chantillon `SRR3405783`) :

```bash
$ tree
.
â”œâ”€â”€ counts
â”‚   â””â”€â”€ SRR3405783
â”‚       â”œâ”€â”€ abundances.cxb
â”‚       â””â”€â”€ count_SRR3405783.txt
â”œâ”€â”€ genome
â”‚   â”œâ”€â”€ genes.gtf
â”‚   â””â”€â”€ genome.fa
â”œâ”€â”€ genome_index
â”‚   â”œâ”€â”€ chrLength.txt
â”‚   â”œâ”€â”€ chrNameLength.txt
â”‚   â”œâ”€â”€ chrName.txt
â”‚   â”œâ”€â”€ chrStart.txt
â”‚   â”œâ”€â”€ exonGeTrInfo.tab
â”‚   â”œâ”€â”€ exonInfo.tab
â”‚   â”œâ”€â”€ geneInfo.tab
â”‚   â”œâ”€â”€ Genome
â”‚   â”œâ”€â”€ genomeParameters.txt
â”‚   â”œâ”€â”€ Log.out
â”‚   â”œâ”€â”€ SA
â”‚   â”œâ”€â”€ SAindex
â”‚   â”œâ”€â”€ sjdbInfo.txt
â”‚   â”œâ”€â”€ sjdbList.fromGTF.out.tab
â”‚   â”œâ”€â”€ sjdbList.out.tab
â”‚   â””â”€â”€ transcriptInfo.tab
â”œâ”€â”€ reads
â”‚   â”œâ”€â”€ SRR3405783.fastq.gz
â”‚   â”œâ”€â”€ SRR3405784.fastq.gz
â”‚   â””â”€â”€ SRR3405785.fastq.gz
â”œâ”€â”€ reads_map
â”‚   â”œâ”€â”€ SRR3405783_Aligned.out.bam
â”‚   â”œâ”€â”€ SRR3405783_Aligned.sorted.out.bam
â”‚   â”œâ”€â”€ SRR3405783_Aligned.sorted.out.bam.bai
â”‚   â”œâ”€â”€ SRR3405783_Log.final.out
â”‚   â”œâ”€â”€ SRR3405783_Log.out
â”‚   â”œâ”€â”€ SRR3405783_Log.progress.out
â”‚   â”œâ”€â”€ SRR3405783_SJ.out.tab
â”‚   â””â”€â”€ SRR3405783__STARgenome
â”‚       â”œâ”€â”€ exonGeTrInfo.tab
â”‚       â”œâ”€â”€ exonInfo.tab
â”‚       â”œâ”€â”€ geneInfo.tab
â”‚       â”œâ”€â”€ sjdbInfo.txt
â”‚       â”œâ”€â”€ sjdbList.fromGTF.out.tab
â”‚       â”œâ”€â”€ sjdbList.out.tab
â”‚       â””â”€â”€ transcriptInfo.tab
â”œâ”€â”€ reads_qc
â”‚   â”œâ”€â”€ SRR3405783_fastqc.html
â”‚   â””â”€â”€ SRR3405783_fastqc.zip
[...]
```


Affichez enfin la taille occupÃ©e par chaque sous-rÃ©pertoire ainsi que la taille totale avec la commande :

```bash
$ du -csh *
5.3M    counts
24M     genome
117M    genome_index
2.5G    reads
1.5G    reads_map
1.1M    reads_qc
[...]
4.1G    total
```

## Optimiser l'analyse d'un Ã©chantillon

L'analyse prÃ©cÃ©dente est complÃ¨tement automatisÃ©e par un script Bash qui rassemble toutes les Ã©tapes de l'analyse, mais l'analyse d'un seul Ã©chantillon prend environ 25 minutes.

Combien de temps faudrait-il pour analyser 3 Ã©chatillons ?

Combien de temps faudrait-il pour analyser les 50 Ã©chantillons de *S. cerevisiae* ?

Nous allons essayer d'optimiser l'analyse d'un Ã©chantillon pour rÃ©duire le temps de calcul. Une premiÃ¨re approche consiste Ã  utiliser plusieurs processeurs (coeurs) pour les logiciels qui le supporte. C'est le cas pour `star` et `cuffquant`.

- STAR propose l'option `--runThreadN x` pour utiliser `x` coeurs. 
- Cuffquant propose l'option `--num-threads x` pour utiliser `x` coeurs.

```{note}
Tous les logiciels ne proposent pas le multi-threading, c'est-Ã -dire l'utilisation de plusieurs coeurs. `htseq-count` par exemple ne prend pas en charge le multi-threading. Pour chaque logiciel, il faut donc le vÃ©rifier et trouver l'option adÃ©quate.
```

TÃ©lÃ©chargez un nouveau script Bash, [`script_local_2.sh`](script_local_2.sh), avec la commande `wget` :

```bash
$ wget https://raw.githubusercontent.com/pierrepo/unix-tutorial/master/tuto2/script_local_2.sh
```

Ouvrez ce script avec l'Ã©diteur de texte de JupyterLab. Essayer de trouver les diffÃ©rences avec le script prÃ©cÃ©dent.

````{admonition} Solution
:class: tip, dropdown

Lors de l'utilisation de `STAR` pour l'indexation du gÃ©nome de rÃ©fÃ©rence et l'alignement des *reads* sur le gÃ©nome, l'option `--runThreadN 4` a Ã©tÃ© ajoutÃ©e pour utiliser 4 coeurs.

Lors de l'utilisation de `cuffquant` pour le comptage des transcrits, l'option `--num-threads 4` a Ã©tÃ© ajoutÃ©e pour utiliser 4 coeurs.
````

Supprimez les rÃ©pertoires qui contiennet les rÃ©sultats de l'analyse prÃ©cÃ©dente :

```bash
$ rm -rf genome_index reads_qc reads_map counts
```

Puis lancez ce nouveau script :

```bash
$ bash script_local_2.sh
```

VÃ©rifiez que le dÃ©roulement du script se passe bien. Quelle Ã©tape vous semble la plus longue ?

Normalement, le temps de calcul est passÃ© de 25 minutes Ã  environ 20 minutes. C'est mieux, mais cela reprÃ©sente toujours beaucoup d'heures de calcul pour analyser les 50 Ã©chantillons. Nous verrons lors de la prochaine session commment utiliser la puissance d'un cluster de calcul pour rÃ©duire le temps d'analyse. ðŸš€

Mais pour le moment, nous allons automatiser le traitement de plusieurs Ã©chantillons dans un mÃªme script Bash.


## RÃ©pÃ©ter une action en Bash

Une boucle permet de rÃ©pÃ©ter un ensemble d'instructions.

Voici un exemple en Bash :

```bash
$ for prenom in gaelle bertrand pierre
> do
> echo "Salut ${prenom} !"
> done
Salut gaelle !
Salut bertrand !
Salut pierre !
```

En sacrifiant un peu de lisibilitÃ©, la mÃªme commande peut s'Ã©crire sur une seule ligne :

```bash
$ for prenom in gaelle bertrand pierre; do echo "Salut ${prenom} !"; done
Salut gaelle !
Salut bertrand !
Salut pierre !
```

Notez l'utilisation du symbole `;` pour sÃ©parer les diffÃ©rents Ã©lÃ©ments de la boucle.

Une leÃ§on de Software Carpentry aborde la notion de [boucle](https://swcarpentry.github.io/shell-novice/05-loop.html). Prenez quelques minutes pour parcourir cette leÃ§on et comprendre de quoi il s'agit.


## Automatiser l'analyse de 3 Ã©chantillons

Le script [`script_local_3.sh`](script_local_3.sh) utilise une boucle pour automatiser l'analyse de plusieurs Ã©chantillons. TÃ©lÃ©chargez-le avec la commande :

```bash
$ wget https://raw.githubusercontent.com/pierrepo/unix-tutorial/master/tuto2/script_local_3.sh
```

Ouvrez ce script avec l'Ã©diteur de texte de JupyterLab (ou avec `less` dans un terminal). Observez la structure du script et essayez de comprendre son fonctionnement.

- La ligne `set -euo pipefail` tout au dÃ©but du script va arrÃªter celui-ci :
    - Ã  la premiÃ¨re erreur ;
    - si une variable n'est pas dÃ©finie ;
    - si une erreur est rencontrÃ©e dans une commande avec un *pipe* (`|`).

    C'est une mesure de sÃ©curitÃ© importante pour votre script. Si vous le souhaitez, vous pouvez lire l'article de Aaron Maxwell Ã  ce sujet : [Use the Unofficial Bash Strict Mode (Unless You Looove Debugging)](http://redsymbol.net/articles/unofficial-bash-strict-mode/)

- Remarquez Ã©galement la structure de la boucle qui va automatiser le traitement des 3 Ã©chantillons.

- PrÃªtez Ã©galement attention, Ã  la toute derniÃ¨re Ã©tape, en dehors de la boucle, qui normalise les comptages des transcrits entre tous les Ã©chantillons.

- Enfin, la dernier ligne contient l'instruction `date` qui affiche la date et l'heure lorsque le script se termine. En ayant notÃ© l'heure Ã  laquelle le script a Ã©tÃ© lancÃ©, cela vous permettra de calculer le temps d'exÃ©cution du script.

Lancez le script `script_local_3.sh`. Comme ce script va automatiser toute l'analyse, il va fonctionner pendant plus d'une heure.

```bash
$ bash script_local_3.sh
```

VÃ©rifiez rÃ©guliÃ¨rement votre terminal qu'aucune erreur n'apparaÃ®t. Une fois terminÃ©, calculez le temps d'exÃ©cution du script.

Le fichier qui contient le comptage normalisÃ© des transcrits est `counts/genes.count_table`.


## Comparer les versions des logiciels utilisÃ©s dans Galaxy (si vous avez du temps)

Connectez-vous maintenant Ã  votre compte sur Galaxy. Essayez de retrouver les versions des logiciels que vous avez utilisÃ©s (FastQC, STAR, samtools, HTSeq, Cufflinks).

Pour ce faire, dans votre *History*, cliquez sur le nom d'un rÃ©sultat d'analyse, puis cliquez sur le petit i entourÃ© (â„¹ï¸) et lisez les informations de la section *Job Dependencies*.

Comparez les versions des logiciels disponibles dans Galaxy avec celles que vous avez utilisÃ©s sur le cluster.

Comment utilisez-vous la version particuliÃ¨re d'un outil dans Galaxy ?


## Conclusion

Vous avez automatisÃ© votre analyse RNA-seq en regroupant les diffÃ©rentes Ã©tapes dans un script Bash. Vous avez Ã©galement utilisÃ© plusieurs coeurs pour accÃ©lÃ©rer autant que possible l'analyse. Enfin, vous avez automatisÃ© l'analyse de plusieurs Ã©chantillons dans un mÃªme script.

Ce n'est pas encore complÃ¨tement satisfaisant. En effet, il vous faudrait 17 heures de calcul pour analyser les 50 Ã©chantillons.

Quelles autres pistes pourriez-vous explorer pour rÃ©duire le temps de calcul ?

Nous en discuterons lors de la prochaine session...


## Bonus : aggrÃ©ger les donnÃ©es produites par HTSeq-count

Si vous analysez plusieurs Ã©chantillons, vous souhaiterez peut-Ãªtre aggrÃ©ger tous les fichiers produits par HTSeq-count.

Les instructions Bash suivantes pourront vous y aider :

```bash
for name in counts/*/*.txt
do
    echo "${name}"
    # On rÃ©cupÃ¨re le nom de l'Ã©chantillon
    sample="$(basename -s .txt ${name} | sed 's/count_//g' )"
    # On stocke dans un fichier temporaire pour chaque Ã©chantillon
    # un entÃªte avec "gene" et le nom de l'Ã©chantillon
    echo -e "${sample}" > "count_${sample}_tmp.txt"
    # On copie le contenu du fichier de comptage dans ce fichier temporaire
    cut -f2 "${name}" >> "count_${sample}_tmp.txt"
done

# On rÃ©cupÃ¨re les noms des gÃ¨nes
echo "gene" > genes.txt
cut -f1 "${name}" >> genes.txt

# On fusionne tous les fichiers
paste genes.txt *tmp.txt > count_all.txt

# On supprime les lignes qui dÃ©butent par '__'
# et qui ne sont pas utiles
grep -v "^__" count_all.txt > count_all_clean.txt

# On supprime les fichiers temporaires
rm -f genes.txt *tmp.txt count_all.txt
```
