# Automatiser l'analyse RNA-seq avec un cluster üöÄ

```{contents}
```

## D√©couvrir le cluster

Un cluster de calcul met √† disposition de ses utilisateurs des processeurs et de la m√©moire vive pour r√©aliser des calculs. Ces ressouces sont r√©parties sur plusieurs machines, appel√©es *n≈ìuds de calcul*. Chaque n≈ìud de calcul contient plusieurs dizaines de processeurs (ou coeurs) et plusieurs centaines de Go de m√©moire vive.

Plusieurs utilisateurs utilisent simultan√©ment un cluster de calcul. Pour vous en rendre compte, dans JupyterLab, ouvrez un terminal puis entrez la commande suivante qui va lister tous les calculs (appel√©s *job*) en cours sur le cluster :

```bash
$ squeue -t RUNNING
```

```{admonition} Rappel
:class: tip
Ne tapez pas le caract√®re `$` en d√©but de ligne et faites bien attention aux majuscules et au minuscules.
```

Vous voyez que vous n'√™tes pas seul ! Comptez maintenant le nombre de jobs en cours d'ex√©cution en cha√Ænant la commande pr√©c√©dente avec `wc -l` :

```bash
$ squeue -t RUNNING | wc -l
```

Vous pouvez aussi compter le nombre de jobs en attente d'ex√©cution :

```bash
$ squeue -t PENDING | wc -l
```

Et vous alors ? Avez-vous lanc√© un calcul ? V√©rifiez-le en entrant la commande suivante qui va lister les calculs en cours pour votre compte :

```bash
$ squeue -u $USER
```

La colonne `ST` indique le statut de votre job :

- `CA` (*cancelled*) : le job a √©t√© annul√©
- `F` (*failed*) : le job a plant√©
- `PD` (*pending*) : le job est en attente que des ressources soient disponibles
- `R` (*running*) : le job est en cours d'ex√©cution

Bizarre ! Vous avez un job avec le statut *running* en cours d'ex√©cution alors que vous n'avez a priori rien lanc√© ü§î

En fait, le JupyterLab dans lequel vous √™tes est lui-m√™me un job lanc√© sur le cluster. C'est d'ailleurs pour cela qu'avant de lancer JupyterLab, vous avez d√ª pr√©ciser le compte √† utiliser (`202304_duo`) et choisir le nombre de processeurs et la quantit√© de m√©moire vive dont vous aviez besoin.

Comme plusieurs utilisateurs peuvent lancer des jobs sur un cluster, un gestionnaire de jobs (ou ordonnanceur) s'occupe de r√©partir les ressources entre les diff√©rents utilisateurs. Sur le cluster de l'IFB, le gestionnaire de jobs est [Slurm](https://slurm.schedmd.com/). D√©sormais le lancement de vos analyses se fera via Slurm.

## Analyser un √©chantillon

D√©placez-vous le r√©pertoire `/shared/projects/202304_duo/$USER/rnaseq` puis v√©rifiez que vous √™tes dans le bon r√©pertoire avec la commande `pwd`.

Supprimez les r√©pertoires qui contiennent les r√©sultats d'une √©ventuelle pr√©c√©dente analyse :

```bash
$ rm -rf genome_index reads_qc reads_map counts
```

T√©l√©chargez dans un terminal de JupyterLab un premier script Bash ([`script_cluster_0.sh`](script_cluster_0.sh)) avec la commande `wget` :

```bash
$ wget https://raw.githubusercontent.com/pierrepo/unix-tutorial/master/tuto3/script_cluster_0.sh
```

Ce script est le script `script_local_2.sh` adapt√© pour une utilisation sur un cluster. Ouvrez ce script avec l'√©diteur de texte de JupyterLab et essayez d'identifier les diff√©rences avec `script_local_2.sh`. 

1. Au d√©but du script, deux lignes sont nouvelles :

    ```
    #SBATCH --mem=2G
    #SBATCH --cpus-per-task=8
    ```

    Ces lignes commencent par le caract√®re `#` qui indique qu'il s'agit de commentaires pour Bash, elles seront donc ignor√©es par le *shell*. Par contre, elles ont un sens tr√®s particulier pour le gestionnaire de jobs du cluster Slurm. Ces lignes indiquent √† Slurm que le job a besoin de 2 Go de m√©moire vive et de 8 processeurs pour s'ex√©cuter.

2. Un peu plus loin, on indique explicitement les modules (les logiciels) √† charger avec leurs versions :

    ```bash
    module load fastqc/0.11.9
    module load star/2.7.9a
    module load samtools/1.14
    module load htseq/0.13.5
    module load cufflinks/2.2.1
    ```

2. De plus, √† l'√©tape d'indexation du g√©nome de r√©f√©rence, dans la ligne

    ```
    srun STAR --runThreadN "${SLURM_CPUS_PER_TASK}" \
    ```

    la variable `SLURM_CPUS_PER_TASK` est utilis√©e pour indiquer √† STAR le nombre de processeurs √† utiliser. Cette variable est automatiquement d√©finie par Slurm lors de l'ex√©cution du script. Dans le cas pr√©sent, elle vaut 8. Le lancement de `STAR` est pr√©c√©d√© de l'instruction `srun` qui va explicitement indique √† Slurm qu'il s'agit d'un sous-job. Nous en verrons l'utilit√© plus tard.


Lancez enfin le script avec la commande suivante :

```bash
$ sbatch -A 202304_duo script_cluster_0.sh
```

Vous devriez obtenir un message du type `Submitted batch job 33332280`. Ici, `33332280` correspond au num√©ro du job. Notez bien le num√©ro de votre job.


- L'instruction `sbatch` est la mani√®re de demander √† Slurm de lancer un script.
- L'option `-A 202304_duo` sp√©cifie quel projet utiliser (facturer) pour cette commande. Un m√™me utilisateur peut appartenir √† plusieurs projets. Le nombre d'heures de calcul attribu√©es √† un projet √©tant limit√©, il est important de savoir quel projet imputer pour telle ou telle commande. Pensez-y pour vos futurs projets.

V√©rifiez que votre script est en train de tourner avec la commande :

```bash
$ squeue -u $USER
```

Et pour avoir plus de d√©tails, utilisez la commande :

$ sacct --format=JobID,JobName,State,Start,Elapsed,CPUTime,NodeList -j JOBID

avec `JOBID` (en fin de ligne) le num√©ro de votre job √† remplacer par le v√¥tre.

Voici un exemple de sortie que vous pourriez obtenir :

```bash
$ sacct --format=JobID,JobName,State,Start,Elapsed,CPUTime,NodeList -j 33332280
       JobID    JobName      State               Start    Elapsed    CPUTime        NodeList 
------------ ---------- ---------- ------------------- ---------- ---------- --------------- 
33332280     script_cl+    RUNNING 2023-05-10T00:11:56   00:01:10   00:09:20     cpu-node-19 
33332280.ba+      batch    RUNNING 2023-05-10T00:11:56   00:01:10   00:09:20     cpu-node-19 
33332280.0         STAR  COMPLETED 2023-05-10T00:11:57   00:00:10   00:01:20     cpu-node-19 
33332280.1       fastqc    RUNNING 2023-05-10T00:12:07   00:00:59   00:07:52     cpu-node-19
```

Quand la colonne *State* est √† `COMPLETED`, cela signifie que le sous-job est termin√©. Un sous-job est cr√©√© √† chaque fois que la commande `srun` est utilis√©e dans le script de soumission. Ici, on voit que le sous-job `STAR` est termin√©, mais que le sous-job `fastqc` est toujours en cours d'ex√©cution.

Relancez r√©guli√®rement la commande pr√©c√©dente pour suivre l'avancement de votre job.

Quand vous avez termin√© l'alignement sur le g√©nome de r√©f√©rence , c'est-√†-dire que vous avez obtenu un second sous-job `STAR` avec le statut `COMPLETED`, stopper le job en cours avec la commande :

```bash
$ scancel JOBID
```

avec `JOBID` le num√©ro de votre job √† remplacer par le v√¥tre.


```{note}
Le fichier `slurm-JOBID.out` (avec `JOBID` le num√©ro de votre job) contient le ¬´ journal ¬ª de votre job. C'est-√†-dire tout ce qui s'affiche habituellement √† l'√©cran a √©t√© enregistr√© dans ce fichier.

Ouvrez ce fichier avec l'√©diteur de texte de JupyterLab pour vous en rendre compte.
```

## Analyser 50 √©chantillons

Maintenant que nous savons comment analyser un √©chantillon avec un cluster de calcul, nous allons automatiser l'analyse de 50 √©chantillons. Mais pour cela nous prendre plusieurs pr√©cautions :

- Nous allons s√©parer les √©tapes suivantes :
    1. Indexer le g√©nome de r√©f√©rence -- ne doit ce que faire une seule fois.
    2. Contr√¥ler la qualit√©, aligner et quantifier les *reads* -- qui doit se faire pour chaque √©chantillon, donc 50 fois.
    3. Normaliser les comptages de tous les √©chantillons ensemble -- ne doit ce que faire une seule fois.
- L'√©tape 2 ne doit pas se faire successivement pour chaque √©chantillon, mais en parall√®le. C'est-√†-dire qu'on souhaite id√©alement lancer l'analyse des 50 √©chantillons **en m√™me temps**.

### Pr√©parer les donn√©es

Nous avons pr√©parer pour vous les 50 √©chantillons (fichiers .fastq.gz) ainsi que le g√©nome de r√©f√©rencee et ses annotations dans le r√©pertoire `/shared/projects/202304_duo/data/rnaseq_scere`. V√©rifiez son contenu avec la commande :

```bash
$ tree /shared/projects/202304_duo/data/rnaseq_scere
```

### Lancer le script de l'√©tape 1

Supprimez les r√©pertoires qui contiennent les r√©sultats d'une √©ventuelle pr√©c√©dente analyse :

```bash
$ rm -rf genome_index reads_qc reads_map counts
```

T√©l√©chargez dans un terminal de JupyterLab le script Bash ([`script_cluster_1.sh`](script_cluster_1.sh)) avec la commande `wget` :

```bash
$ wget https://raw.githubusercontent.com/pierrepo/unix-tutorial/master/tuto3/script_cluster_1.sh
```
Ouvrez ce script avec l'√©diteur de texte de JupyterLab et essayez d'identifier comment sont d√©finies les variables `base_dir` et `data_dir`.

Puis lancez le script en n'oubliant pas d'indiquer explicitement le compte √† utiliser (`202304_duo`) :

```bash
$ sbatch -A 202304_duo script_cluster_1.sh
```

V√©rifiez avec les commandes `squeue` et `sacct` que le job est lanc√© et se termine correctement (normalement rapidement).

```{rappel}
Le fichier `slurm-JOBID.out` (avec `JOBID` le num√©ro de votre job) contient le ¬´ journal ¬ª de votre job. N'h√©sitez pas √† le consulter.
```

### Lancer le script de l'√©tape 2


T√©l√©chargez dans un terminal de JupyterLab le script Bash ([`script_cluster_2.sh`](script_cluster_2.sh)) avec la commande `wget` :

```bash
$ wget https://raw.githubusercontent.com/pierrepo/unix-tutorial/master/tuto3/script_cluster_2.sh
```
Ouvrez ce script avec l'√©diteur de texte de JupyterLab. Notez en d√©but de script la ligne 

```
#SBATCH --array=0-49 
```

qui nous permettra de cr√©er un *job array*, c'est-√†-dire un ensemble de 50 (de 0 √† 49 inclus) sous-jobs qui vont √™tre lanc√©s en parall√®le.

Pour chacun des sous-job, on lui attribue un √©chantillon avec les commandes suivantes :

```bash
# liste de tous les fichiers .fastq.gz dans un tableau
fastq_files=(${fastq_dir}/*fastq.gz)
# extraction de l'identifiant de l'√©chantillon
# √† partir du nom de fichier : /shared/projects/form_2021_29/data/rnaseq_tauri/reads/SRR3405783.fastq.gz
# on extrait : SRR3405783
sample=$(basename -s .fastq.gz "${fastq_files[$SLURM_ARRAY_TASK_ID]}")
```

Cette √©tape est importante car elle permet de savoir quel √©chantillon traiter pour chaque sous-job. Par exemple, le sous-job 0 va √™tre associ√© √† l'√©chantillon `SRR3405783` (le premier par ordre alphab√©tique).

Pour ne pas emboliser le cluster et pour que tout le monde puisse obtenir des r√©sultats, modifier la ligne 

```
#SBATCH --array=0-49 
```

par

```
#SBATCH --array=0-4
```

Vous n'analyserez que 5 √©chantillons dans 5 jobs en parall√®le.  Pensez √† sauvegarder vos modifications.

Lancez enfin le script :

```bash
$ sbatch -A 202304_duo script_cluster_2.sh
```

Suivez la progression de vos jobs avec la commande :

```bash
$ sacct --format=JobID,JobName,State,Start,Elapsed,CPUTime,NodeList -j JOBID
```

avec `JOBID` le num√©ro de votre job.

Vous avez m√©rit√© une pause caf√© ‚òïÔ∏è


Plut√¥t que de relancer en permanence la commande `sacct` vous pouvez demander √† la commande `watch` d'afficher les √©ventuels changements :

```bash
$ watch sacct --format=JobID,JobName,State,Start,Elapsed,CPUTime,NodeList -j JOBID
```

```{hint}
Utilisez la combinaison de touches <kbd>Ctrl</kbd> + <kbd>C</kbd> pour arr√™ter la commande `watch`.
```

### Lancer le script de l'√©tape 3